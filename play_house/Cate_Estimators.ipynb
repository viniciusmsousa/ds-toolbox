{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Wip] Cate Example\n",
    "\n",
    "The objective os this notebook is to build a causal inference model based on the paper by Athey, Imbens 2015 using dataset from cunning 2021.\n",
    "\n",
    "Specifically we want to:\n",
    "1. Explain the dataset;\n",
    "2. Compute the Real ATE;\n",
    "3. Compute The propensity score & transform Y (used in both next two stages);\n",
    "4. Estimate the ATE from biased data;\n",
    "5. Estimate the Cate from biased data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session Setup\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor \n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "from ds_toolbox.utils import start_local_spark\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "spark = start_local_spark(max_mem=1, n_cores=1)\n",
    "\n",
    "# Functions\n",
    "def read_data(file): \n",
    "    return pd.read_stata(\"https://raw.github.com/scunning1975/mixtape/master/\" + file)\n",
    "\n",
    "get_p1 = F.udf(lambda value: value[1].item(), FloatType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) The dataset\n",
    "\n",
    "Describe the datasets here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----+----+-----+----+----+--------+----+----+-----------------+------+-------+-----+---------+---+---+\n",
      "|             data_id|treat| age|educ|black|hisp|marr|nodegree|re74|re75|             re78|  age2|   age3|educ2|educ_re74|u74|u75|\n",
      "+--------------------+-----+----+----+-----+----+----+--------+----+----+-----------------+------+-------+-----+---------+---+---+\n",
      "|Dehejia-Wahba Sample|  1.0|37.0|11.0|  1.0| 0.0| 1.0|     1.0| 0.0| 0.0|  9930.0458984375|1369.0|50653.0|121.0|      0.0|  1|  1|\n",
      "|Dehejia-Wahba Sample|  1.0|22.0| 9.0|  0.0| 1.0| 0.0|     1.0| 0.0| 0.0| 3595.89404296875| 484.0|10648.0| 81.0|      0.0|  1|  1|\n",
      "|Dehejia-Wahba Sample|  1.0|30.0|12.0|  1.0| 0.0| 0.0|     0.0| 0.0| 0.0|   24909.44921875| 900.0|27000.0|144.0|      0.0|  1|  1|\n",
      "|Dehejia-Wahba Sample|  1.0|27.0|11.0|  1.0| 0.0| 0.0|     1.0| 0.0| 0.0| 7506.14599609375| 729.0|19683.0|121.0|      0.0|  1|  1|\n",
      "|Dehejia-Wahba Sample|  1.0|33.0| 8.0|  1.0| 0.0| 0.0|     1.0| 0.0| 0.0|289.7898864746094|1089.0|35937.0| 64.0|      0.0|  1|  1|\n",
      "+--------------------+-----+----+----+-----+----+----+--------+----+----+-----------------+------+-------+-----+---------+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DataFrame Experimental\n",
    "dfs_experimental = spark.createDataFrame(read_data('nsw_mixtape.dta'))\n",
    "\n",
    "#DataFrame with Bias selection\n",
    "dfs_biased = dfs_experimental.union(spark.createDataFrame(read_data('cps_mixtape.dta')))\\\n",
    "    .withColumn('age2', F.col('age')**2)\\\n",
    "    .withColumn('age3', F.col('age')**3)\\\n",
    "    .withColumn('educ2', F.col('educ')**2)\\\n",
    "    .withColumn('educ_re74', F.col('educ')*F.col('re74'))\\\n",
    "    .withColumn('u74', F.when(F.col('re74')==0, 1).otherwise(0))\\\n",
    "    .withColumn('u75', F.when(F.col('re75')==0, 1).otherwise(0))\n",
    "\n",
    "\n",
    "dfs_biased.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) The Real ATE\n",
    "Since this was as random experiment we can easily compute the real average treatment effect to use as a benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = 6349.14 - 4554.8 = 1794.34\n"
     ]
    }
   ],
   "source": [
    "mean0 = dfs_experimental.filter(F.col('treat')==0).select(F.avg('re78')).collect()[0][0]\n",
    "mean1 = dfs_experimental.filter(F.col('treat')==1).select(F.avg('re78')).collect()[0][0]\n",
    "\n",
    "print(f'ATE = {round(mean1, 2)} - {round(mean0, 2)} = {round(mean1-mean0, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Computing Propensity Score & Transform Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>treat</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>black</th>\n",
       "      <th>hisp</th>\n",
       "      <th>marr</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>re74</th>\n",
       "      <th>re75</th>\n",
       "      <th>re78</th>\n",
       "      <th>age2</th>\n",
       "      <th>age3</th>\n",
       "      <th>educ2</th>\n",
       "      <th>educ_re74</th>\n",
       "      <th>u74</th>\n",
       "      <th>u75</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>ps</th>\n",
       "      <th>th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1574.423950</td>\n",
       "      <td>625.0</td>\n",
       "      <td>15625.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.3435121024079386, -1.3435121024079386]</td>\n",
       "      <td>[0.79306691210761, 0.20693308789238996]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206933</td>\n",
       "      <td>1985.234715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6181.879883</td>\n",
       "      <td>625.0</td>\n",
       "      <td>15625.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.36373033285875067, -0.36373033285875067]</td>\n",
       "      <td>[0.5899431415709895, 0.4100568584290105]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.410057</td>\n",
       "      <td>10478.771609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1923.937988</td>\n",
       "      <td>841.0</td>\n",
       "      <td>24389.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.1351501830741899, 0.1351501830741899]</td>\n",
       "      <td>[0.4662637895374044, 0.5337362104625956]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.533736</td>\n",
       "      <td>4126.286725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2321.106934</td>\n",
       "      <td>324.0</td>\n",
       "      <td>5832.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.580757579049262, -1.580757579049262]</td>\n",
       "      <td>[0.829311782887994, 0.170688217112006]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170688</td>\n",
       "      <td>2798.835121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4814.626953</td>\n",
       "      <td>324.0</td>\n",
       "      <td>5832.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.2772102295195165, -1.2772102295195165]</td>\n",
       "      <td>[0.7819745215886744, 0.21802547841132558]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218025</td>\n",
       "      <td>6157.012486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                data_id  treat   age  educ  black  hisp  marr  nodegree  re74  \\\n",
       "0  Dehejia-Wahba Sample    1.0  25.0  11.0    1.0   0.0   1.0       1.0   0.0   \n",
       "1  Dehejia-Wahba Sample    1.0  25.0   5.0    1.0   0.0   0.0       1.0   0.0   \n",
       "2  Dehejia-Wahba Sample    1.0  29.0   8.0    1.0   0.0   0.0       1.0   0.0   \n",
       "3  Dehejia-Wahba Sample    1.0  18.0  12.0    1.0   0.0   0.0       0.0   0.0   \n",
       "4  Dehejia-Wahba Sample    1.0  18.0  11.0    1.0   0.0   0.0       1.0   0.0   \n",
       "\n",
       "   re75         re78   age2     age3  educ2  educ_re74  u74  u75  \\\n",
       "0   0.0  1574.423950  625.0  15625.0  121.0        0.0    1    1   \n",
       "1   0.0  6181.879883  625.0  15625.0   25.0        0.0    1    1   \n",
       "2   0.0  1923.937988  841.0  24389.0   64.0        0.0    1    1   \n",
       "3   0.0  2321.106934  324.0   5832.0  144.0        0.0    1    1   \n",
       "4   0.0  4814.626953  324.0   5832.0  121.0        0.0    1    1   \n",
       "\n",
       "                                 rawPrediction  \\\n",
       "0    [1.3435121024079386, -1.3435121024079386]   \n",
       "1  [0.36373033285875067, -0.36373033285875067]   \n",
       "2    [-0.1351501830741899, 0.1351501830741899]   \n",
       "3      [1.580757579049262, -1.580757579049262]   \n",
       "4    [1.2772102295195165, -1.2772102295195165]   \n",
       "\n",
       "                                 probability  prediction        ps  \\\n",
       "0    [0.79306691210761, 0.20693308789238996]         0.0  0.206933   \n",
       "1   [0.5899431415709895, 0.4100568584290105]         0.0  0.410057   \n",
       "2   [0.4662637895374044, 0.5337362104625956]         1.0  0.533736   \n",
       "3     [0.829311782887994, 0.170688217112006]         0.0  0.170688   \n",
       "4  [0.7819745215886744, 0.21802547841132558]         0.0  0.218025   \n",
       "\n",
       "             th  \n",
       "0   1985.234715  \n",
       "1  10478.771609  \n",
       "2   4126.286725  \n",
       "3   2798.835121  \n",
       "4   6157.012486  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=['age', 'age2', 'age3', 'educ', 'educ2', 'marr', 'nodegree', 'black', 'hisp', 're74', 're75', 'u74', 'u75', 'educ_re74']\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "pipeline = Pipeline(stages = [assembler, LogisticRegression(labelCol='treat', fitIntercept=True)])\n",
    "fitted_classifier = pipeline.fit(dfs_biased)\n",
    "\n",
    "\n",
    "dfs_predicted_with_ps_th = fitted_classifier.transform(dfs_biased)\\\n",
    "    .withColumn('ps', get_p1(F.col('probability')))\\\n",
    "    .withColumn('th', F.col('re78')*(F.col('treat')*F.col('ps'))/(F.col('ps')*(1-F.col('ps'))))\n",
    "\n",
    "dfs_predicted_with_ps_th.sample(fraction=0.05).orderBy(F.col('treat').desc()).toPandas().drop(columns=['features']).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Estimating ATE from Bieased Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Estimating the CATE from Biased Data\n",
    "\n",
    "Steps\n",
    "* a) Compute the propensity score os treatment;\n",
    "* b) Transform the Y variable into Y*;\n",
    "* c) Predict Y* (normal prediction procedures);\n",
    "* d) Evaluate step c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest: Starting\n",
      "random_forest: Fitting Pipeline\n",
      "random_forest: Making Predictions on test data\n"
     ]
    }
   ],
   "source": [
    "target = 'th'\n",
    "train, test = dfs_predicted_with_ps_th.select('features', 'th').randomSplit([0.8, 0.2], seed=12345)\n",
    "\n",
    "spark_classifiers = {\n",
    "    #'logistic_regression': LinearRegression(labelCol=target),\n",
    "    #  'decision_tree': DecisionTreeRegressionModel(predictionCol=target),\n",
    "      'random_forest': RandomForestRegressor(labelCol=target),\n",
    "    #  'gradient_boosting': GBTRegressionModel(predictionCol=target)\n",
    "}\n",
    "\n",
    "for classifier_name, classifier in spark_classifiers.items():\n",
    "    print(f'{classifier_name}: Starting')\n",
    "    pipeline = Pipeline(stages = [classifier])\n",
    "    # Fit no Modelo de Predict nos test\n",
    "    print(f'{classifier_name}: Fitting Pipeline')\n",
    "    fitted_classifier = pipeline.fit(train)\n",
    "    print(f'{classifier_name}: Making Predictions on test data')\n",
    "    prediction_on_test = fitted_classifier.transform(test)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+\n",
      "|            features|                th|        prediction|\n",
      "+--------------------+------------------+------------------+\n",
      "|(14,[0,1,2,3,4,6,...|13386.756789547962| 634.2559682630944|\n",
      "|(14,[0,1,2,3,4,7,...|               0.0|2025.1604229086108|\n",
      "|(14,[0,1,2,3,4,7,...|               0.0|2025.1604229086108|\n",
      "|(14,[0,1,2,3,4,7,...|               0.0|3748.7449887462244|\n",
      "|(14,[0,1,2,3,4,7,...|               0.0|  3533.86533323607|\n",
      "|(14,[0,1,2,3,4,7,...|47712.014965533985|3993.8831559332148|\n",
      "|(14,[0,1,2,3,4,7,...|               0.0|4553.7725196473475|\n",
      "|(14,[0,1,2,3,4,11...| 8135.580899398114| 260.0003933968165|\n",
      "|[17.0,289.0,4913....|               0.0| 1290.459031397421|\n",
      "|[17.0,289.0,4913....|               0.0| 1290.459031397421|\n",
      "|[17.0,289.0,4913....|               0.0| 1290.459031397421|\n",
      "|[18.0,324.0,5832....|               0.0|1351.4932181314593|\n",
      "|[18.0,324.0,5832....|               0.0|1351.4932181314593|\n",
      "|[18.0,324.0,5832....|               0.0|1351.4932181314593|\n",
      "|[18.0,324.0,5832....|               0.0| 83.80835904651063|\n",
      "|[18.0,324.0,5832....|               0.0| 1290.459031397421|\n",
      "|[18.0,324.0,5832....|               0.0| 1290.459031397421|\n",
      "|[18.0,324.0,5832....|13548.900257442743|1736.0481053153671|\n",
      "|[18.0,324.0,5832....| 12464.10745565036| 593.2994495538529|\n",
      "|[18.0,324.0,5832....|               0.0|1251.2601958997334|\n",
      "+--------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_on_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55ca833fdd3f1ee413ab439547b925c5593b89af16821ba7de853a7aaaa05354"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ds-toolbox-HgP-t3cq-py3.8': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
