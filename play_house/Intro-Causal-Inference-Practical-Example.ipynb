{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Wip] Cate Example\n",
    "\n",
    "The objective os this notebook is to build a causal inference model based on the paper by Athey, Imbens 2015 using dataset from cunning 2021.\n",
    "\n",
    "Specifically we want to:\n",
    "1. Explain the dataset;\n",
    "2. Compute the Real ATE;\n",
    "3. Compute The propensity score & transform Y (used in both next two stages);\n",
    "4. Estimate the ATE from biased data;\n",
    "5. Estimate the Cate from biased data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vini/Dev-Files/Poetry/virtualenvs/ds-toolbox-HgP-t3cq-py3.8/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session Setup\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, DecisionTreeRegressor, GBTRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "from ds_toolbox.utils import start_local_spark\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "spark = start_local_spark(max_mem=1, n_cores=1)\n",
    "\n",
    "# Functions\n",
    "def read_data(file): \n",
    "    return pd.read_stata(\"https://raw.github.com/scunning1975/mixtape/master/\" + file)\n",
    "\n",
    "get_p1 = F.udf(lambda value: value[1].item(), FloatType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) The dataset\n",
    "\n",
    "Describe the datasets here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----+----+-----+----+----+--------+----+----+-----------------+------+-------+-----+---------+---+---+\n",
      "|             data_id|treat| age|educ|black|hisp|marr|nodegree|re74|re75|             re78|  age2|   age3|educ2|educ_re74|u74|u75|\n",
      "+--------------------+-----+----+----+-----+----+----+--------+----+----+-----------------+------+-------+-----+---------+---+---+\n",
      "|Dehejia-Wahba Sample|  1.0|37.0|11.0|  1.0| 0.0| 1.0|     1.0| 0.0| 0.0|  9930.0458984375|1369.0|50653.0|121.0|      0.0|  1|  1|\n",
      "|Dehejia-Wahba Sample|  1.0|22.0| 9.0|  0.0| 1.0| 0.0|     1.0| 0.0| 0.0| 3595.89404296875| 484.0|10648.0| 81.0|      0.0|  1|  1|\n",
      "|Dehejia-Wahba Sample|  1.0|30.0|12.0|  1.0| 0.0| 0.0|     0.0| 0.0| 0.0|   24909.44921875| 900.0|27000.0|144.0|      0.0|  1|  1|\n",
      "|Dehejia-Wahba Sample|  1.0|27.0|11.0|  1.0| 0.0| 0.0|     1.0| 0.0| 0.0| 7506.14599609375| 729.0|19683.0|121.0|      0.0|  1|  1|\n",
      "|Dehejia-Wahba Sample|  1.0|33.0| 8.0|  1.0| 0.0| 0.0|     1.0| 0.0| 0.0|289.7898864746094|1089.0|35937.0| 64.0|      0.0|  1|  1|\n",
      "+--------------------+-----+----+----+-----+----+----+--------+----+----+-----------------+------+-------+-----+---------+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DataFrame Experimental\n",
    "dfs_experimental = spark.createDataFrame(read_data('nsw_mixtape.dta'))\n",
    "\n",
    "# DataFrame with Bias selection\n",
    "dfs_biased = dfs_experimental.union(spark.createDataFrame(read_data('cps_mixtape.dta')))\\\n",
    "    .withColumn('age2', F.col('age')**2)\\\n",
    "    .withColumn('age3', F.col('age')**3)\\\n",
    "    .withColumn('educ2', F.col('educ')**2)\\\n",
    "    .withColumn('educ_re74', F.col('educ')*F.col('re74'))\\\n",
    "    .withColumn('u74', F.when(F.col('re74')==0, 1).otherwise(0))\\\n",
    "    .withColumn('u75', F.when(F.col('re75')==0, 1).otherwise(0))\n",
    "\n",
    "\n",
    "dfs_biased.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) The Real ATE\n",
    "Since this was as random experiment we can easily compute the real average treatment effect to use as a benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Real ATE = 6349.14 - 4554.8 = 1794.34\n",
      "---------\n",
      "The Bias ATE = 6349.14 - 14682.01 = -8332.87\n"
     ]
    }
   ],
   "source": [
    "mean0 = dfs_experimental.filter(F.col('treat')==0).select(F.avg('re78')).collect()[0][0]\n",
    "mean1 = dfs_experimental.filter(F.col('treat')==1).select(F.avg('re78')).collect()[0][0]\n",
    "print(f'The Real ATE = {round(mean1, 2)} - {round(mean0, 2)} = {round(mean1-mean0, 2)}')\n",
    "\n",
    "print('---------')\n",
    "mean0 = dfs_biased.filter(F.col('treat')==0).select(F.avg('re78')).collect()[0][0]\n",
    "mean1 = dfs_biased.filter(F.col('treat')==1).select(F.avg('re78')).collect()[0][0]\n",
    "print(f'The Bias ATE = {round(mean1, 2)} - {round(mean0, 2)} = {round(mean1-mean0, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Computing Propensity Score & Transform Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>treat</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>black</th>\n",
       "      <th>hisp</th>\n",
       "      <th>marr</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>re74</th>\n",
       "      <th>re75</th>\n",
       "      <th>re78</th>\n",
       "      <th>age2</th>\n",
       "      <th>age3</th>\n",
       "      <th>educ2</th>\n",
       "      <th>educ_re74</th>\n",
       "      <th>u74</th>\n",
       "      <th>u75</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>ps</th>\n",
       "      <th>th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>529.0</td>\n",
       "      <td>12167.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6276138681249268, -0.6276138681249268]</td>\n",
       "      <td>[0.6519482173540334, 0.3480517826459666]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348052</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3972.540039</td>\n",
       "      <td>400.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.9882236807497957, -0.9882236807497957]</td>\n",
       "      <td>[0.7287369232969796, 0.2712630767030204]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271263</td>\n",
       "      <td>5451.267532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>485.229797</td>\n",
       "      <td>625.0</td>\n",
       "      <td>15625.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.4402154675084553, -0.4402154675084553]</td>\n",
       "      <td>[0.6083103711428268, 0.3916896288571732]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391690</td>\n",
       "      <td>797.668169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1849.0</td>\n",
       "      <td>79507.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.8906931022971243, -0.8906931022971243]</td>\n",
       "      <td>[0.7090331838382283, 0.29096681616177167]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290967</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>385.274109</td>\n",
       "      <td>8124.714844</td>\n",
       "      <td>361.0</td>\n",
       "      <td>6859.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.719669028722274, -0.719669028722274]</td>\n",
       "      <td>[0.6725341307727755, 0.32746586922722454]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327466</td>\n",
       "      <td>12080.747442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                data_id  treat   age  educ  black  hisp  marr  nodegree  re74  \\\n",
       "0  Dehejia-Wahba Sample    1.0  23.0  11.0    1.0   0.0   0.0       1.0   0.0   \n",
       "1  Dehejia-Wahba Sample    1.0  20.0  11.0    1.0   0.0   0.0       1.0   0.0   \n",
       "2  Dehejia-Wahba Sample    1.0  25.0  11.0    1.0   0.0   0.0       1.0   0.0   \n",
       "3  Dehejia-Wahba Sample    1.0  43.0   9.0    1.0   0.0   0.0       1.0   0.0   \n",
       "4  Dehejia-Wahba Sample    1.0  19.0  10.0    1.0   0.0   0.0       1.0   0.0   \n",
       "\n",
       "         re75         re78    age2     age3  educ2  educ_re74  u74  u75  \\\n",
       "0    0.000000     0.000000   529.0  12167.0  121.0        0.0    1    1   \n",
       "1    0.000000  3972.540039   400.0   8000.0  121.0        0.0    1    1   \n",
       "2    0.000000   485.229797   625.0  15625.0  121.0        0.0    1    1   \n",
       "3    0.000000     0.000000  1849.0  79507.0   81.0        0.0    1    1   \n",
       "4  385.274109  8124.714844   361.0   6859.0  100.0        0.0    1    0   \n",
       "\n",
       "                               rawPrediction  \\\n",
       "0  [0.6276138681249268, -0.6276138681249268]   \n",
       "1  [0.9882236807497957, -0.9882236807497957]   \n",
       "2  [0.4402154675084553, -0.4402154675084553]   \n",
       "3  [0.8906931022971243, -0.8906931022971243]   \n",
       "4    [0.719669028722274, -0.719669028722274]   \n",
       "\n",
       "                                 probability  prediction        ps  \\\n",
       "0   [0.6519482173540334, 0.3480517826459666]         0.0  0.348052   \n",
       "1   [0.7287369232969796, 0.2712630767030204]         0.0  0.271263   \n",
       "2   [0.6083103711428268, 0.3916896288571732]         0.0  0.391690   \n",
       "3  [0.7090331838382283, 0.29096681616177167]         0.0  0.290967   \n",
       "4  [0.6725341307727755, 0.32746586922722454]         0.0  0.327466   \n",
       "\n",
       "             th  \n",
       "0      0.000000  \n",
       "1   5451.267532  \n",
       "2    797.668169  \n",
       "3      0.000000  \n",
       "4  12080.747442  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=['age', 'age2', 'age3', 'educ', 'educ2', 'marr', 'nodegree', 'black', 'hisp', 're74', 're75', 'u74', 'u75', 'educ_re74']\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "pipeline = Pipeline(stages = [assembler, LogisticRegression(labelCol='treat', fitIntercept=True)])\n",
    "fitted_classifier = pipeline.fit(dfs_biased)\n",
    "\n",
    "\n",
    "dfs_predicted_with_ps_th = fitted_classifier.transform(dfs_biased)\\\n",
    "    .withColumn('ps', get_p1(F.col('probability')))\\\n",
    "    .withColumn(\n",
    "        'th',\n",
    "        F.col('re78')*(F.col('treat')*F.col('ps'))/(F.col('ps')*(1-F.col('ps')))\n",
    "    )\n",
    "\n",
    "dfs_predicted_with_ps_th.sample(fraction=0.05).orderBy(F.col('treat').desc()).toPandas().drop(columns=['features']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Estimating the CATE and ATE from Biased Data\n",
    "\n",
    "Steps\n",
    "* a) Compute the propensity score os treatment;\n",
    "* b) Transform the Y variable into Y*;\n",
    "* c) Predict Y* (normal prediction procedures);\n",
    "* d) Evaluate step c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'th'\n",
    "train, test = dfs_predicted_with_ps_th.select('features', 'treat', 're78', 'th').randomSplit([0.8, 0.2], seed=12345)\n",
    "\n",
    "spark_classifiers = {\n",
    "    'logistic_regression': LinearRegression(labelCol=target),\n",
    "    'decision_tree': DecisionTreeRegressor(labelCol=target),\n",
    "    'random_forest': RandomForestRegressor(labelCol=target),\n",
    "    'gradient_boosting': GBTRegressor(labelCol=target)\n",
    "}\n",
    "\n",
    "\n",
    "df_evaluate = pd.DataFrame()\n",
    "\n",
    "for classifier_name, classifier in spark_classifiers.items():\n",
    "    print(f'{classifier_name}: Starting')\n",
    "    pipeline = Pipeline(stages = [classifier])\n",
    "    # Fit no Modelo de Predict nos test\n",
    "    print(f'{classifier_name}: Fitting Pipeline')\n",
    "    fitted_classifier = pipeline.fit(train)\n",
    "    print(f'{classifier_name}: Making Predictions on test data')\n",
    "    prediction_on_test = fitted_classifier.transform(test)\n",
    "\n",
    "    df_temp = pd.DataFrame({\n",
    "        'model':[classifier_name],\n",
    "        'msqe': [prediction_on_test.withColumn('sqe', -(F.col('th')-F.col('prediction'))**2).select(F.sum('sqe')).collect()[0][0]],\n",
    "        'ate': [prediction_on_test.filter(F.col('treat')==1).select(F.avg('prediction')).collect()[0][0]-prediction_on_test.filter(F.col('treat')==0).select(F.avg('prediction')).collect()[0][0]]\n",
    "    })\n",
    "    df_evaluate = df_evaluate.append(df_temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluate.sort_values('msqe', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rascunho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean0 = dfs_biased.filter(F.col('treat')==0).select(F.avg('re78')).collect()[0][0]\n",
    "mean1 = dfs_biased.filter(F.col('treat')==1).select(F.avg('re78')).collect()[0][0]\n",
    "\n",
    "print(f'ATE = {round(mean1, 2)} - {round(mean0, 2)} = {round(mean1-mean0, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55ca833fdd3f1ee413ab439547b925c5593b89af16821ba7de853a7aaaa05354"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ds-toolbox-HgP-t3cq-py3.8': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
